{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MXNET_CPU_WORKER_NTHREADS=4\n"
     ]
    }
   ],
   "source": [
    "%env MXNET_CPU_WORKER_NTHREADS=4\n",
    "import scipy.io as sio\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "mx.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_name, train, tune):\n",
    "    #loads the .mat file in file_name\n",
    "    #returns a dictionary data, containing test, train and tune\n",
    "    #the original data file is a dict with key 'X', containing the data\n",
    "    #training is X[:,0:train-1], tune is X[:,train:train+tune-1]\n",
    "    #test is the rest\n",
    "    data_dict = sio.loadmat(file_name)\n",
    "    data_matr = data_dict['X']\n",
    "    data_matr = np.array(data_matr)\n",
    "    (d,n) = data_matr.shape\n",
    "    if (n <= train):\n",
    "        sys.exit(\"train >= number of points\")\n",
    "    data_train = data_matr[:,0:train]\n",
    "    data_train /= np.max(np.abs(data_train))\n",
    "    if (n <= train+tune):\n",
    "        sys.exit(\"train+tune >= number of points\")\n",
    "    data_tune = data_matr[:,train:train+tune]\n",
    "    data_tune /= np.max(np.abs(data_tune))\n",
    "    data_test = data_matr[:,train+tune:]\n",
    "    data_test /= np.max(np.abs(data_test))\n",
    "    data = {\"train\":data_train,\"tune\":data_tune,\"test\":data_test}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_data('./data/xsmnist.mat', 8000, 1999)\n",
    "data['test'] = data['tune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 1999)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()\n",
    "data['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ctx = mx.cpu()\n",
    "model_ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30170732793\n"
     ]
    }
   ],
   "source": [
    "(d,n) = data['train'].shape\n",
    "k = 1\n",
    "u, s, vt = svds(np.dot(data['test'],data['test'].T)/(data['test'].shape)[1],k)\n",
    "obj_val = sum(s)\n",
    "print (obj_val)\n",
    "batch_size = 1;\n",
    "train_data = mx.gluon.data.DataLoader(data['train'].T, batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(data['test'].T, batch_size, shuffle=False)\n",
    "#train_data = mx.nd.array(data['train'])\n",
    "#test_data = mx.nd.array(data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train_err \n",
      "[ 1.177549]\n",
      "<NDArray 1 @cpu(0)>, Test_err \n",
      "[ 1.17804921]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Epoch 1. Train_err \n",
      "[ 1.04018283]\n",
      "<NDArray 1 @cpu(0)>, Test_err \n",
      "[ 1.04080641]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Epoch 2. Train_err \n",
      "[ 0.79537845]\n",
      "<NDArray 1 @cpu(0)>, Test_err \n",
      "[ 0.79587299]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Epoch 3. Train_err \n",
      "[ 0.61238325]\n",
      "<NDArray 1 @cpu(0)>, Test_err \n",
      "[ 0.61175948]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Epoch 4. Train_err \n",
      "[ 0.39780205]\n",
      "<NDArray 1 @cpu(0)>, Test_err \n",
      "[ 0.39197528]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Epoch 5. Train_err \n",
      "[ 0.31499761]\n",
      "<NDArray 1 @cpu(0)>, Test_err \n",
      "[ 0.31334871]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Epoch 6. Train_err \n",
      "[ 0.1942122]\n",
      "<NDArray 1 @cpu(0)>, Test_err \n",
      "[ 0.19247532]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Epoch 7. Train_err \n",
      "[ 0.13182962]\n",
      "<NDArray 1 @cpu(0)>, Test_err \n",
      "[ 0.12810647]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Epoch 8. Train_err \n",
      "[ 0.08859444]\n",
      "<NDArray 1 @cpu(0)>, Test_err \n",
      "[ 0.07792294]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-df260b9b8e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcompare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/mxnet/ndarray/ndarray.pyc\u001b[0m in \u001b[0;36mT\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m     \u001b[0;31m# pylint: enable= invalid-name, undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/mxnet/ndarray/op.pyc\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(data, axes, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/mxnet/_ctypes/ndarray.pyc\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         return _ndarray_cls(ctypes.cast(output_vars[0], NDArrayHandle),\n\u001b[0m\u001b[1;32m     98\u001b[0m                             stype=out_stypes[0])\n\u001b[1;32m     99\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ctypes/__init__.pyc\u001b[0m in \u001b[0;36mcast\u001b[0;34m(obj, typ)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0m_cast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPYFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_void_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0m_string_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPYFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_void_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_string_at_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "U = nd.random_normal(shape = (d,k), ctx=model_ctx)\n",
    "Q,L = nd.linalg.gelqf(U.T)\n",
    "U = Q.T\n",
    "U.attach_grad()\n",
    "def proj_matr(x_loading):\n",
    "    return nd.dot(U,x_loading)\n",
    "\n",
    "def net(X, U_matr):\n",
    "    #return U\n",
    "    x_loading = nd.dot(U_matr.T, X)\n",
    "    return proj_matr(x_loading)\n",
    "\n",
    "def eval_loss(yhat,y):\n",
    "    return -0.5*nd.dot(yhat,y)\n",
    "    #yhat = proj_matr(nd.dot(U.T,y))\n",
    "    #return -0.5*nd.dot(yhat.T,y)\n",
    "\n",
    "def SGD(U_matr, eta, compare, do_qr = False):\n",
    "    #print nd.norm(compare+U_matr.grad)\n",
    "    #print (eta)\n",
    "    U_matr[:] = U_matr - eta*U_matr.grad\n",
    "    if(do_qr):\n",
    "        Q,L = nd.linalg.gelqf(U_matr.T)\n",
    "        U_matr = Q.T\n",
    "        \n",
    "'''def evaluate_accuracy(data_iterator, net, U_matr, true_obj):\n",
    "    curr_obj = 0.0\n",
    "    Q,L = nd.linalg.gelqf(U_matr.T)\n",
    "    U_matr = Q.T\n",
    "    for i,data in enumerate(data_iterator):\n",
    "        data = data.as_in_context(model_ctx).astype(dtype='float32')\n",
    "        proj_data = net(data.T, U_matr)\n",
    "        curr_obj += nd.norm(nd.dot(U_matr.T,data.T))*nd.norm(nd.dot(U_matr.T,data.T))\n",
    "    return true_obj - curr_obj/(1.0*(i+1))'''\n",
    "\n",
    "def evaluate_accuracy(data, U_matr, true_obj):\n",
    "    Q,L = nd.linalg.gelqf(U_matr.T)\n",
    "    U_matr = Q.T\n",
    "    data = nd.array(data)\n",
    "    obj_sqrt = nd.norm(nd.dot(U_matr.T,data))\n",
    "    return true_obj - obj_sqrt*obj_sqrt/(data.shape)[1]\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = .05\n",
    "\n",
    "for e in range(epochs):\n",
    "    #cumulative_loss = 0\n",
    "    for i, data_t in enumerate(train_data):\n",
    "        data_t = data_t.as_in_context(model_ctx).astype(dtype='float32')\n",
    "        with autograd.record():\n",
    "            output = net(data_t.T, U)\n",
    "            loss = eval_loss(output.T,data_t.T)\n",
    "        loss.backward()\n",
    "        compare = nd.dot(data_t.T,nd.dot(data_t,U))\n",
    "        SGD(U, learning_rate/(i+1),compare)\n",
    "        #print(nd.norm(nd.dot(U.T,nd.array(u))))\n",
    "        #cumulative_loss += nd.sum(loss).asscalar()\n",
    "        #if(i%100==0):\n",
    "            #print(\"Current objective: %s\", evaluate_accuracy(data['train'], U, obj_val))\n",
    "        \n",
    "    test_accuracy = evaluate_accuracy(data['test'], U, obj_val)\n",
    "    train_accuracy = evaluate_accuracy(data['train'], U, obj_val)\n",
    "    print(\"Epoch %s. Train_err %s, Test_err %s\" % (e, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
